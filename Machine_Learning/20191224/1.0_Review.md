## 12월 24일 전날 복습리뷰

### 분류(Classification) 

- 예측 대상의 속성(설명변수)을 입력받아서  목표변수(종속변수)가 갖고 있는 
  카테고리(범주형) 값 중 하나의 값으로 예측하는 분석 방법
- 분류 분석 유형(알고리즘)
  - KNN, SVM, Decision Tree, Logistic Regression

#### 1. KNN

- 새로운 관측값이 주어지면 기존 데이터 중에서 가장 속성이 비슷한 k개의 이웃을 먼저 찾아서 
  가까운 이웃들이 갖고 있는 목표변수(종속변수)값과 같은 값으로 분류 , 예측
  최근접점을 몇개로 할 것인지 지정하는  K는 홀수, 작은 값 설정 권장
  KNN은 기존 데이터 사이의 거리를 재서 이웃을 뽑습니다. 
  - 거리 측정 방법에 따라 결과가 달라지는 알고리즘
- ※ 설명변수들을 정규화 (sklearn.preprocessing모듈의 StandardScaler())
  훈련 데이터와 검증 데이터 분리 - sklearn.model selection, sklearn.preprocessing모듈의 train_test_split()
  학습(훈련)으로부터 만들어진 모델의 예측 능력(정확도, 재현율, F1) 평가에 사용되는 도구- confusion_matrix()
  예측 능력(정확도, 재현율, F1) 평가 지표 계산 - sklearn.metrics모듈의  classification_report()

KNN의 하이퍼파라미터 - k개수,  거리측정 방법
K가 작을 경우  overfitting
K가 커질수록  경우 underfitting 

#### 2. SVM

- 데이터를 오직 공간상의 정보(선)만으로 이진 분류 분석 할때 사용

- 데이터 간의 마진을 최대가 되는 선을 그어 분류 

- 3차원 데이터, 2차원의 면으로 데이터를 집단 분류

  - 커널 트릭, 커널 함수 매핑

    SVM은 동일한 분류 값을 갖는 데이터끼리 같은 공간에 위치하도록 벡터 공간을 여러 조각으로 나눌 수 있는 분류 방법
    SVM은 노이즈에 영향을 받지 않으며, overfiting될 가능성이 낮음
    SVM 의 하이퍼파라미터 - cost, gamma(r), kernal

한번에 하나씩 설명변수를 사용해서 예측가능한 규칙들의 집합을 생성하는 알고리즘 
데이터를 분석해서 데이터 사이에 존재하는 패턴을 예측 가능한 규칙들의 조합으로 표현->나무모향
root node ->규칙 조건으로 분기 -> ... -> leaf node 또는 ternimal node
ternimal node들의 데이터 개수의 합 = root node의 데이터 개수
분류된 데이터 집합 수는 ternimal node의 수가 됨
범주형 데이터, 연속형 수치 데이터 모두 분류, 예측 가능
sklearn.tree모듈의 DecisionTreeClassifier()
DecisionTree 하이퍼 파라미터 - 각 노드의 순도는 증가시키고 , 불순도(불확실성)는 감소
분류오차(가지 분기 기준)

#### 군집(cluster) - 데이터(관측값)가 가지는 여러 속성들을 분석해서 서로 비슷한 특성을 갖는 데이터끼리 그룹핑하는 알고리즘
클러스터내의 데이터들은 유사한 속성을 가지며 다른 클러스터와의 속성은 완전히 구별되는 속성을 가진다
정답이 없는 비지도 학습
#### K-Means -  유사한 데이터들의 클러스터 중심점까지의 거리를 이용
sklearn.cluster  모듈 - KMeans(n_clusters= , )
분류된 클러스터 결과 값은 KMeans객체.labels_



