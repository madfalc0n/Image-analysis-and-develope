```
#########################ReView##################################################################
퍼셉트론 :
입력값과 활성화 함수를 사용해서 출력 값을 다음으로 넘기기는 가장 작은  인공 신경망 단위
N개의 이진수가 하나의 뉴런을 통과해서 가중합이 0보다 크면 활성화되는 가장 간단한 신경망 구조
초평면(hyperplane)으로 구분되는 두개의 공간을 분리하는 역할 - AND게이트, OR게이트를 만들 수 있다
XOR게이트를 퍼셉트론으로 구현하기 위해서는 좌표 평면 자체에 변화를 주는 은닉층을 만들어서 공간을 왜곡하면 두 영역으로 분류 가능
XOR게이트를 퍼셉트론으로 구현하기 위해서는 두개의 퍼셉트론을 한번에 계산할 수 있어야 합니다.

퍼셉트론 신경망 수행 흐름 :
환경변수 지정(출력뉴런수, 입력데이터에 적용할 가중치, 가중합에 적용될 바이어스, 활성화함수, 은닉층 수) ->신경망 실행-> 결과를 실제값과 비교 -> 계산된 오차를 출력층과 은닉층의 가중치를 수정 (오차 역전파)  -> 신경망 실행 ->....-> 결과 출력 (분류, 예측)
신경망 내부에서 가중치는 오차 역전파 방법을 사용해 수정합니다.

은닉층으로의 출력에 사용될 활성화 함수 : 기울기 소실문제를 해결해주는 ReLU를 주로 사용
출력층에 사용될 활성화 함수 :  Sigmoid(이항분류), softmax(다항분류),  선형회귀(연속형변수의 값 예측) X

[성능 최적화 함수 ]
모든 데이터에 대해서 미분값 계산은 수행 속도 저하가 발생  ->  랜덤하게 추출한 일부 데이터를 사용해서 더 빠르게 수행 (SGD, 확률적 경사 하강법)
모멘텀 -관성을 이용하여 방향을 고려해서 진동 폭을 줄이기 위해 사용 
알엠에스프롭(RMSprop) - 아다그라드 보폭 민감도를 보완한 방법
아담 - 모멘텀+ 알엠에스프롭(RMSprop)

Sequential() - keras에서 제공하는 모델 구조를 구성할수 이는 객체 
add(Dense(출력뉴런수  ,input_dim= , init= , activation=)) : 입력층 -> 은닉층  구조(layer)
add(Dense(출력뉴런수, activation=)) : 은닉층 -> 은닉층 구조(layer)
add(Dense(1, activation=))   은닉층 -> 출력층 구조(layer)
 
1 epoch  : 학습 프로세스에서 모든 샘플에 대해서 한번 실행되는 것  
다중 분류시에 class가 object타입으로  thin, normal, fat ->정수변환(LabelEncoder) -> one-hot-encoding 변환 (keras.utils.np_utils.to_categorial())

Sequential() 를 이용해서 신경망 layer구성 후
compile(loss=오차함수, optimizer=성능최적화 함수, metrics=정확도, 재현율등 측정 함수) 
fit(독립변수데이터 객체, 종속변수 데이터객체,  epochs=,  batch_size=) 학습 

[오차 함수]
mean_squared_error : 평균제곱 오차 
mean_absolute_error : 평균 절대 오차 
mean_absolute_percentage_error :평균 절대 백분율 오차 
mean_squared_logartithmetic_error : 평균제곱  로그 오차 
분류 문제에서 정확률과 재현률 측정  -  categorial_crossentropy(범주형 교차 엔트로피), binary_crossentropy(이항 교차 엔트로피)

train_testsplit(독립변수데이터 객체, 종속변수 데이터객체,  test_size=,  random_state=)  : 학습데이터와 테스트 데이터 분리

학습 결과 모델을 저장 :  save()
학습 결과 모델을 메모리로 로딩 : load_model()

k겹 교차 검증 - 학습데이터(테스트 데이터)가 적을 경우 , 데이터셋을 여러 개로 나누어 하나씩 테스트 셋으로 사용( 전체 데이터를 테스트셋으로 사용 할 수 있음)
sklearn.model_selection.StratifiedKFold(n_splits= , shuffle=,  random_state=)

keras.callbacks.ModelCheckpoint(filepath=,  monitor=,  verbose=, save_best_only=) :Epoch마다 모델의 정확도를 기록 저장 

Epoch마다   생성된 모델 객체에는 배열로 학습 정확도acc,  검증 정확도val_acc, 학습 손실값loss, 검증 손실값 val_loss

과적합이 발생하기 시작됨을 생성된 모델 객체의 테스트의 오차 속성 val_loss 값이 감소하다가 다시 증가하기 시작하면 ...
과적합이 발생하면 신경망 학습 수행 중단 : EarlyStopping(monitor='val_loss', patience=)

Dense Layer마다 출력 뉴런수 설정(제약이 없다)

Dense Layer 구조, 개수등의 설정에 따라 모델의 성능이 달라지므로 , Dense 생성시에 변경가능한 옵션들, Layer수등을 조정해서 튜닝합니다.(하이퍼파라미터 튜닝)
fit()의 기본 로그는 손실값과 정확도가 표시됩니다.
이진분류는 정확도를 통해서 제대로 학습이 되고 있는지  확인 가능
다중 분류는 정확도, 재현율등...학습이 되고 있는지  확인 가능
metrics 는 평가 기준

evalute(독립변수데이터 객체, 종속변수 데이터객체, metrics=) - 모델을 평가,  손실값 및 metrics 값등을 반환
```