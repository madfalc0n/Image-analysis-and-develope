{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM으로 BMI 판정\n",
    "1. 키의 최대값은 200cm, 몸무게의 최대값은 100kg으로 정규화\n",
    "2. 저체중(thin), 정상(normal), 비만(fat) 레이블을 one-hot-encoding [1, 0, 0], [0, 1, 0], [0, 0, 1]로 변환\n",
    "3. 소프트 맥스 회귀방법 , 오차 함수는 교차 엔트로피 사용\n",
    "4. 교차 엔트로피  - 2개의 확률 분포 사이에 정의되는 척도로서 교차 엔트로피 값이 작을 수록 정확한 값을 냄\n",
    "5. 학습 계수 0.01, 경사 하강법(steepest descent method) 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 0 오차= 108.66269 정확률(평균)= 0.3242\n",
      "Epoch= 500 오차= 57.58866 정확률(평균)= 0.8904\n",
      "Epoch= 1000 오차= 45.020916 정확률(평균)= 0.898\n",
      "Epoch= 1500 오차= 41.654335 정확률(평균)= 0.9566\n",
      "Epoch= 2000 오차= 34.664024 정확률(평균)= 0.943\n",
      "Epoch= 2500 오차= 34.287025 정확률(평균)= 0.9674\n",
      "Epoch= 3000 오차= 26.880762 정확률(평균)= 0.9726\n",
      "Epoch= 3500 오차= 29.590666 정확률(평균)= 0.9728\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/bmi.csv')\n",
    "df\n",
    "#키와 몸무게에 대해 정규화\n",
    "df['height'] = df['height'] / 200\n",
    "df['weight'] = df['weight'] / 100\n",
    "#one-hot encoding , thin[1, 0, 0], normal[0, 1, 0], fat[0, 0, 1]\n",
    "bclass = {'thin': [1,0,0] , 'normal':[0, 1, 0], 'fat':[0, 0, 1]}\n",
    "df['label_pat'] = df['label'].apply(lambda x: np.array(bclass[x]))\n",
    "df.head(3)\n",
    "\n",
    "#학습 데이터와 테스트 데이터 분류\n",
    "test_df = df[15000:20000]\n",
    "test_pat= test_df[[\"weight\", \"height\"]]\n",
    "test_ans = list(test_df[\"label_pat\"])\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None,2]) #키 , 몸무게 데이터 담을 placeholder 선언\n",
    "Y = tf.placeholder(tf.float32, [None,3]) #정답 레이블 데이터 담을 placeholder 선언\n",
    "\n",
    "W = tf.Variable(tf.zeros([2,3])) #가중치\n",
    "b = tf.Variable(tf.zeros([3])) #바이어스\n",
    "y = tf.nn.softmax(tf.matmul(X,W) + b) #소프트맥스 회귀 정의, 배열X에 가중치 W 곱하고 바이어스 b 더함\n",
    "\n",
    "#오차함수 - 교차 엔트로피\n",
    "cross_entropy = -tf.reduce_sum(Y * tf.log(y))  \n",
    "#경사하강법으로 학습\n",
    "train= tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)  \n",
    "\n",
    "#예측값, 정답률 계산\n",
    "predict = tf.equal(tf.argmax(y, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(predict, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) \n",
    "for step in range(3501):\n",
    "    i = (step*100) % 14000\n",
    "    rows = df[i+1:i+1+100]\n",
    "    x_pat = rows[[\"weight\", \"height\"]]\n",
    "    y_ans =  list(rows[\"label_pat\"])\n",
    "    sess.run(train, feed_dict={X: x_pat  , Y: y_ans })\n",
    "    if step%500  == 0 :\n",
    "        cre = sess.run(cross_entropy, feed_dict={X: x_pat  , Y: y_ans })\n",
    "        acc = sess.run(accuracy , feed_dict={X: test_pat  , Y: test_ans })\n",
    "        print(\"Epoch=\", step, \"오차=\", cre, \"정확률(평균)=\", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras 모델로 BMI 판정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n",
      "C:\\Users\\student\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "Train on 13500 samples, validate on 1500 samples\n",
      "Epoch 1/20\n",
      "13500/13500 [==============================] - 1s 56us/step - loss: 0.5147 - accuracy: 0.7993 - val_loss: 0.2765 - val_accuracy: 0.9133\n",
      "Epoch 2/20\n",
      "13500/13500 [==============================] - 1s 47us/step - loss: 0.2551 - accuracy: 0.8964 - val_loss: 0.1549 - val_accuracy: 0.9687\n",
      "Epoch 3/20\n",
      "13500/13500 [==============================] - 1s 46us/step - loss: 0.1912 - accuracy: 0.9202 - val_loss: 0.1219 - val_accuracy: 0.9660\n",
      "Epoch 4/20\n",
      "13500/13500 [==============================] - 1s 43us/step - loss: 0.1663 - accuracy: 0.9264 - val_loss: 0.1333 - val_accuracy: 0.9407\n",
      "Epoch 5/20\n",
      "13500/13500 [==============================] - 1s 40us/step - loss: 0.1513 - accuracy: 0.9326 - val_loss: 0.1104 - val_accuracy: 0.9520\n",
      "Epoch 6/20\n",
      "13500/13500 [==============================] - 1s 42us/step - loss: 0.1462 - accuracy: 0.9384 - val_loss: 0.2176 - val_accuracy: 0.8907\n",
      "Epoch 7/20\n",
      "13500/13500 [==============================] - 1s 41us/step - loss: 0.1368 - accuracy: 0.9421 - val_loss: 0.0753 - val_accuracy: 0.9747\n",
      "Epoch 8/20\n",
      "13500/13500 [==============================] - 1s 42us/step - loss: 0.1417 - accuracy: 0.9388 - val_loss: 0.1164 - val_accuracy: 0.9440\n",
      "Epoch 9/20\n",
      "13500/13500 [==============================] - 1s 41us/step - loss: 0.1249 - accuracy: 0.9453 - val_loss: 0.0661 - val_accuracy: 0.9840\n",
      "Epoch 10/20\n",
      "13500/13500 [==============================] - 1s 42us/step - loss: 0.1250 - accuracy: 0.9458 - val_loss: 0.1192 - val_accuracy: 0.9427\n",
      "Epoch 11/20\n",
      "13500/13500 [==============================] - 1s 42us/step - loss: 0.1210 - accuracy: 0.9480 - val_loss: 0.1633 - val_accuracy: 0.9213\n",
      "4999/4999 [==============================] - 0s 19us/step\n",
      "loss= 0.172187195727529\n",
      "accuracy= 0.9099820256233215\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/bmi.csv\")\n",
    "\n",
    "#키와 몸무게 정규화\n",
    "df[\"height\"] /= 200\n",
    "df[\"weight\"] /= 100\n",
    "\n",
    "X = df[[\"weight\", \"height\"]].as_matrix()\n",
    "\n",
    "#label 컬럼 변환 - thin[1, 0, 0]/normal[0, 1, 0]/fat [0, 0, 1]\n",
    "bclass = {\"thin\": [1, 0, 0] , \"normal\":[0, 1, 0], \"fat\": [0, 0, 1]}\n",
    "Y = np.empty((20000, 3))\n",
    "for i, v in enumerate(df[\"label\"]):\n",
    "    Y[i] = bclass[v]\n",
    "\n",
    "    \n",
    "#학습데이터 , 테스트 데이터 분리\n",
    "X_train, Y_train = X[1:15001], Y[1:15001]\n",
    "X_test, Y_test = X[15001:20001], Y[15001:20001]\n",
    "\n",
    "model = Sequential()  #모델 객체 생성\n",
    "model.add(Dense(512, input_shape=(2, )))    #Dense(노드 수 , ....) 층을 의미하는 객체\n",
    "model.add(Activation('relu'))   # 활성화 함수\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(3))      # 분류하고 싶은 클래스 수 만큼 출력으로 구성\n",
    "model.add(Activation('softmax'))  #활성화 함수\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "hist = model.fit(X_train, Y_train, batch_size=100, nb_epoch=20, validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=2)], verbose=1)\n",
    "                    \n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print(\"loss=\", score[0])\n",
    "print(\"accuracy=\", score[1])\n",
    "\n",
    "\n",
    "\n",
    "# weight decay( 가중치 감소) - 학습중 가중치가 큰 것에 대해서 패널티를 부과해 과적합의 위험을 줄이는 방법\n",
    "# Dropout - 복잡한 신경망에서 가중치 감소만으로 과적합을 피하기 어려운 경우 뉴런의 연결을 임의로 삭제시켜 신호를 전달하지 못하도록 하는 방법\n",
    "# softmax 회귀 - 입력받은 값을 출력으로 0~1사이의 값으로 모두 정규화하여 출력값들의 총합은 항상 1이 되는 특성의 함수\n",
    "#분류하고 싶은 클래스 수 만큼 출력으로 구성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_5:0\", shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([5],dtype=tf.float32)\n",
    "b = tf.constant([10],dtype=tf.float32)\n",
    "c = tf.constant([2],dtype=tf.float32)\n",
    "d = a*b+c\n",
    "print(d)\n",
    "\n",
    "tw = tf.summary.FileWriter(\"log_dir\", graph=sess.graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
